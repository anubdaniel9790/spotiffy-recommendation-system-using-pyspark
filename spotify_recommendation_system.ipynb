{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spotify recommendation system",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zqKaWUXXPOr"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from kafka import KafkaProducer\n",
        "from datetime import datetime\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# pip install kafka-python\n",
        "\n",
        "KAFKA_TOPIC_NAME_CONS = \"songTopic\"\n",
        "KAFKA_BOOTSTRAP_SERVERS_CONS = 'localhost:9092'\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Kafka Producer Application Started ... \")\n",
        "\n",
        "    kafka_producer_obj = KafkaProducer(bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS_CONS,\n",
        "                                       value_serializer=lambda x: x.encode('utf-8'))\n",
        "    \n",
        "    filepath = \"tracks.csv\"\n",
        "    # This is the csv which has Spotify data.\n",
        "    \n",
        "    \n",
        "    songs_df = pd.read_csv(filepath)\n",
        "    #songs_df = songs_df[songs_df['release_date'] > '2020-01-01']\n",
        "    songs_df = songs_df[songs_df['popularity'] > 50]\n",
        "    # We use this filter to get popular songs streaming. This can be tuned based on your intrest.\n",
        "    \n",
        "    \n",
        "    songs_df['order_id'] = np.arange(len(songs_df))\n",
        "    \n",
        "    songs_df['artists'] = songs_df['artists'].str.replace('[^a-zA-Z]', '')\n",
        "    songs_df['id_artists'] = songs_df['id_artists'].str.replace('[^a-zA-Z]', '')\n",
        "    \n",
        "    # Some pre-processing performed for clean data.\n",
        "    \n",
        "    song_list = songs_df.to_dict(orient=\"records\")\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "    message_list = []\n",
        "    message = None\n",
        "    for message in song_list:\n",
        "        \n",
        "        message_fields_value_list = []\n",
        "        \n",
        "        \n",
        "        message_fields_value_list.append(message[\"order_id\"])\n",
        "        message_fields_value_list.append(message[\"id\"])\n",
        "        message_fields_value_list.append(message[\"name\"])\n",
        "        message_fields_value_list.append(message[\"popularity\"])\n",
        "        message_fields_value_list.append(message[\"duration_ms\"])\n",
        "        message_fields_value_list.append(message[\"explicit\"])\n",
        "        message_fields_value_list.append(message[\"artists\"])\n",
        "        message_fields_value_list.append(message[\"id_artists\"])\n",
        "        message_fields_value_list.append(message[\"release_date\"])\n",
        "        message_fields_value_list.append(message[\"danceability\"])\n",
        "        message_fields_value_list.append(message[\"energy\"])\n",
        "        message_fields_value_list.append(message[\"key\"])\n",
        "        message_fields_value_list.append(message[\"loudness\"])\n",
        "        message_fields_value_list.append(message[\"mode\"])\n",
        "        message_fields_value_list.append(message[\"speechiness\"])\n",
        "        message_fields_value_list.append(message[\"acousticness\"])\n",
        "        message_fields_value_list.append(message[\"instrumentalness\"])\n",
        "        message_fields_value_list.append(message[\"liveness\"])\n",
        "        message_fields_value_list.append(message[\"valence\"])\n",
        "        message_fields_value_list.append(message[\"tempo\"])\n",
        "        message_fields_value_list.append(message[\"time_signature\"])\n",
        "\n",
        "\n",
        "\n",
        "        message = ','.join(str(v) for v in message_fields_value_list)\n",
        "        print(\"Message Type: \", type(message))\n",
        "        print(\"Message: \", message)\n",
        "        kafka_producer_obj.send(KAFKA_TOPIC_NAME_CONS, message)\n",
        "        time.sleep(1)\n",
        "\n",
        "\n",
        "    print(\"Kafka Producer Application Completed. \")"
      ],
      "metadata": {
        "id": "3YZPR7d3YJrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.ml.feature import Normalizer, StandardScaler\n",
        "import random\n",
        "\n",
        "import time\n",
        "\n",
        "kafka_topic_name = \"songTopic\"\n",
        "kafka_bootstrap_servers = 'localhost:9092'\n",
        "\n",
        "spark = SparkSession \\\n",
        "        .builder \\\n",
        "        .appName(\"Spotify Streaming Reccomendation System\") \\\n",
        "        .master(\"local[*]\") \\\n",
        "        .getOrCreate()\n",
        "\n",
        "spark.sparkContext.setLogLevel(\"ERROR\")"
      ],
      "metadata": {
        "id": "9tTC3cycYMWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct a streaming DataFrame that reads from test-topic\n",
        "songs_df = spark \\\n",
        "        .readStream \\\n",
        "        .format(\"kafka\") \\\n",
        "        .option(\"kafka.bootstrap.servers\", kafka_bootstrap_servers) \\\n",
        "        .option(\"subscribe\", kafka_topic_name) \\\n",
        "        .option(\"startingOffsets\", \"latest\") \\\n",
        "        .load()\n",
        "\n",
        "songs_df1 = songs_df.selectExpr(\"CAST(value AS STRING)\", \"timestamp\")\n",
        "\n",
        "\n",
        "songs_schema_string = \"order_id INT,id STRING, name STRING,popularity INT, duration_ms DOUBLE, explicit INT, \" \\\n",
        "                           + \"artists STRING, id_artists STRING, release_date STRING, \" \\\n",
        "                           + \"danceability DOUBLE,\" \\\n",
        "                           + \"energy DOUBLE, key INT, loudness DOUBLE, \" \\\n",
        "                           + \"mode INT,\" \\\n",
        "                           + \"speechiness DOUBLE,\" \\\n",
        "                           + \"acousticness DOUBLE, instrumentalness DOUBLE, liveness DOUBLE, \" \\\n",
        "                           + \"valence DOUBLE, tempo DOUBLE, time_signature DOUBLE\"\n",
        "\n",
        "\n",
        "\n",
        "songs_df2 = songs_df1 \\\n",
        "        .select(from_csv(col(\"value\"), songs_schema_string) \\\n",
        "                .alias(\"song\"), \"timestamp\")\n",
        "\n",
        "\n",
        "songs_df3 = songs_df2.select(\"song.*\", \"timestamp\")"
      ],
      "metadata": {
        "id": "66m1CaCPYQD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0VWPCCq3YV91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Favorite song data generated using Spotify API"
      ],
      "metadata": {
        "id": "U8o77tNmYkdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from spotify_api import getSong\n",
        "song_data = getSong.passs()\n",
        "#song_data.rename(columns={'duration_s': 'duration_ms' }, inplace=True)\n",
        "song_data = song_data.drop(['id', 'added_at', 'time_signature','duration_s'], axis='columns')\n",
        "rand_n = random. randint(0,len(song_data)-1)\n",
        "add_df = song_data.head(rand_n)[-1:]"
      ],
      "metadata": {
        "id": "8QwycySDYmYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python\n",
        "# coding: utf-8\n",
        "\n",
        "\n",
        "import os\n",
        "#import my_spotify_credentials as credentials\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ujson\n",
        "import spotipy\n",
        "import spotipy.util\n",
        "import seaborn as sns\n",
        "\n",
        "# fill your credentials here.\n",
        "os.environ[\"SPOTIPY_CLIENT_ID\"] = ''\n",
        "os.environ[\"SPOTIPY_CLIENT_SECRET\"] = ''\n",
        "os.environ[\"SPOTIPY_REDIRECT_URI\"] = ''\n",
        "\n",
        "scope = 'user-library-read'\n",
        "username = ''\n",
        "\n",
        "token = spotipy.util.prompt_for_user_token(username, scope)\n",
        "\n",
        "if token:\n",
        "    spotipy_obj = spotipy.Spotify(auth=token)\n",
        "    saved_tracks_resp = spotipy_obj.current_user_saved_tracks(limit=50)\n",
        "else:\n",
        "    print('Couldn\\'t get token for that username')\n",
        "    \n",
        "number_of_tracks = saved_tracks_resp['total']\n",
        "print('%d tracks' % number_of_tracks)\n",
        "\n",
        "def save_only_some_fields(track_response):\n",
        "    return {        \n",
        "        'id': str(track_response['track']['id']),\n",
        "        'name': str(track_response['track']['name']),\n",
        "        'artists': [artist['name'] for artist in track_response['track']['artists']],\n",
        "        'duration_ms': track_response['track']['duration_ms'],\n",
        "        'popularity': track_response['track']['popularity'],\n",
        "        'added_at': track_response['added_at']\n",
        "    }\n",
        "\n",
        "tracks = [save_only_some_fields(track) for track in saved_tracks_resp['items']]\n",
        "\n",
        "while saved_tracks_resp['next']:\n",
        "    saved_tracks_resp = spotipy_obj.next(saved_tracks_resp)\n",
        "    tracks.extend([save_only_some_fields(track) for track in saved_tracks_resp['items']])\n",
        "\n",
        "\n",
        "tracks_df = pd.DataFrame(tracks)\n",
        "pd.set_option('display.max_rows', len(tracks))\n",
        "\n",
        "\n",
        "tracks_df['artists'] = tracks_df['artists'].apply(lambda artists: artists[0])\n",
        "tracks_df['duration_ms'] = tracks_df['duration_ms'].apply(lambda duration: duration/1000)\n",
        "\n",
        "tracks_df = tracks_df.rename(columns = {'duration_ms':'duration_s'})\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "audio_features = {}\n",
        "\n",
        "for idd in tracks_df['id'].tolist():\n",
        "    audio_features[idd] = spotipy_obj.audio_features(idd)[0]\n",
        "    \n",
        "tracks_df['acousticness'] = tracks_df['id'].apply(lambda idd: audio_features[idd]['acousticness'])\n",
        "tracks_df['speechiness'] = tracks_df['id'].apply(lambda idd: audio_features[idd]['speechiness'])\n",
        "tracks_df['key'] = tracks_df['id'].apply(lambda idd: str(audio_features[idd]['key']))\n",
        "tracks_df['liveness'] = tracks_df['id'].apply(lambda idd: audio_features[idd]['liveness'])\n",
        "tracks_df['instrumentalness'] = tracks_df['id'].apply(lambda idd: audio_features[idd]['instrumentalness'])\n",
        "tracks_df['energy'] = tracks_df['id'].apply(lambda idd: audio_features[idd]['energy'])\n",
        "tracks_df['tempo'] = tracks_df['id'].apply(lambda idd: audio_features[idd]['tempo'])\n",
        "tracks_df['time_signature'] = tracks_df['id'].apply(lambda idd: audio_features[idd]['time_signature'])\n",
        "tracks_df['loudness'] = tracks_df['id'].apply(lambda idd: audio_features[idd]['loudness'])\n",
        "tracks_df['danceability'] = tracks_df['id'].apply(lambda idd: audio_features[idd]['danceability'])\n",
        "tracks_df['valence'] = tracks_df['id'].apply(lambda idd: audio_features[idd]['valence'])\n",
        "\n",
        "\n",
        "class getSong(): \n",
        "    def __init__(self):\n",
        "        super(getSong, self).__init__()\n",
        "        \n",
        "    def passs():\n",
        "\n",
        "        return tracks_df\n"
      ],
      "metadata": {
        "id": "WINlCiG_Y0uR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.sql(\"SELECT * FROM testedTable5\")\n",
        "\n",
        "df = df.sort(df.release_date.desc())\n",
        "\n",
        "df_stream = df\n",
        "\n",
        "df = df.drop('order_id',\n",
        " 'id',\n",
        " 'explicit',\n",
        "  'mode',\n",
        " 'release_date',\n",
        " 'id_artists',\n",
        " 'time_signature',\n",
        " 'duration_ms',\n",
        " 'timestamp')\n",
        "\n",
        "df_sp = spark.createDataFrame(add_df)\n",
        "df = df.union(df_sp)\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "assembler=VectorAssembler(inputCols=[\n",
        " 'danceability',\n",
        " 'energy',\n",
        " 'loudness',\n",
        " 'speechiness',\n",
        " 'acousticness',\n",
        " 'instrumentalness',\n",
        " 'liveness',\n",
        " 'valence',\n",
        " 'tempo'], outputCol='features')\n",
        "assembled_data=assembler.setHandleInvalid(\"skip\").transform(df)"
      ],
      "metadata": {
        "id": "S23UdNPaY1hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StandardScaler\n",
        "scale=StandardScaler(inputCol='features',outputCol='standardized')\n",
        "data_scale=scale.fit(assembled_data)\n",
        "df=data_scale.transform(assembled_data)"
      ],
      "metadata": {
        "id": "EZf7XMArZV0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lDFV-1-KZc3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "K MEANS CLUSTER\n"
      ],
      "metadata": {
        "id": "l8KvLnr1Zdaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.evaluation import ClusteringEvaluator\n",
        "silhouette_score=[]\n",
        "evaluator = ClusteringEvaluator(predictionCol='prediction', featuresCol='standardized', \\\n",
        "                                metricName='silhouette', distanceMeasure='squaredEuclidean')\n",
        "\n",
        "\n",
        "KMeans_algo=KMeans(featuresCol='standardized', k=3)\n",
        "    \n",
        "KMeans_fit=KMeans_algo.fit(df)\n",
        "    \n",
        "output_df =KMeans_fit.transform(df)"
      ],
      "metadata": {
        "id": "pSJTXBBKZfpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "o7bwWLQrZmQh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}